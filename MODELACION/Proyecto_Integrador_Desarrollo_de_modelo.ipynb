{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"logo\"><img src=\"https://raw.githubusercontent.com/Camilorb07/Integrador_S1_2021/main/Imagenes/Logo_EAFIT.png\" width=\"350\"  /></h1>\n",
        "\n",
        "# Proyecto Integrador 1° Semestre\n",
        "\n",
        "<hr style=\"border:2px solid #004B85\"> </hr>\n",
        "\n",
        "\n",
        "## Modelo predicitivo de días estancia hospitalaria como herramienta para optimización de recursos\n",
        "\n",
        "<hr style=\"border:2px solid #004B85\"> </hr>\n",
        "\n",
        "# Maestría en Ciencia de los Datos y Analítica\n",
        "## Grupo 8 - Semestre 2024-2\n",
        "\n",
        "- #### Gustavo Andrés Rubio Castillo\n",
        "- #### Juan Pablo Bertel Morales\n",
        "- #### Gustavo Adolfo Jerez Tous\n",
        "\n",
        "<hr style=\"border:2px solid #004B85\"> </hr>\n",
        "\n",
        "# ¡¡¡Advertencia!!!\n",
        "\n",
        "- Este notebook fue desarrollado en Google Colab PRO."
      ],
      "metadata": {
        "id": "HM9xIrvXvswD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONFIGURACIÓN DE EJECUCIÓN**"
      ],
      "metadata": {
        "id": "ZnkmN0PZv9va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Importante:**\n",
        "Por la dimensionalidad y cardinalidad del dataset en sus variables categóricas, fue necesario ejecutar este notebook en un ambiente Colab PRO, pues los recursos de memoria y procesador utilizados por los algoritmos de reducción de dimensionalidad desbordaban la capacidad de  nuestros computadores personales. Se entiende que para efectos de despliegue en producción del modelo desarrollado esto no es necesario, pues la predicción es soportable por un servidor común dedicado a la ejecución de este tipo de modelos."
      ],
      "metadata": {
        "id": "I_dUn-TXwMeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar librerías que no vienen por defecto en Colab:\n",
        "- pycaret: torneo de modelos\n",
        "- prince: MCA"
      ],
      "metadata": {
        "id": "qExGCz7FbN3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCpDtYaiYj-B",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install prince\n",
        "!pip install pycaret"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silenciar warnings y otras alertas menores"
      ],
      "metadata": {
        "id": "ISOm6snkbonr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "qdK98Fqkq6GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJudgqv0AMbO"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZFnPc_c29tv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import re\n",
        "import pycaret"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar funciones utilitarias propias para visualizar distribución de variables"
      ],
      "metadata": {
        "id": "Y7CJ8svibfLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import funcs_utils as fu"
      ],
      "metadata": {
        "id": "EKdekg5PWjGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6nssbHFp0qK"
      },
      "source": [
        "# **ETAPA 1 - ASEGURAR CALIDAD DEL DATASET**\n",
        "\n",
        "La etapa inicial del proceso, aquí se depura y estandariza el dataset de modelación para que pueda ser procesado más adelante y realizar los análisis estadísticos correspondientes.\n",
        "\n",
        "**Pasos realizados**\n",
        "\n",
        "- Carga del dataset desde S3 bucket(o local)\n",
        "- Definición de variables de modelación y variable de respuesta\n",
        "- Separación de variables numéricas y categóricas para análisis\n",
        "- Limpieza de texto en variables categóricas\n",
        "- Eliminación de registros nulos y duplicados\n",
        "\n",
        "**Resultado final**\n",
        "\n",
        "Dataset limpio y estandarizado para realizar análisis exploratorio de datos (EDA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66IMrRtSrTq0"
      },
      "source": [
        "### Cargar el dataset desde AWS S3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1YtG8oFfbD5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las claves de acceso son temporales, pues estamos restringidos por la licencia educativa para crear usuarios persistentes con credenciales permanentes. En caso de querer probar esta parte de la carga, favor pedirnos la creación de credenciales temporales."
      ],
      "metadata": {
        "id": "3xtbtV0FSUiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#aws_access_key_id=ASIAQ4FS56V3QHBQZA6P\n",
        "#aws_secret_access_key=COPSG9Q3CLAkz/dsOgH93ghVNpNroyX7ptLGx0g2\n",
        "#aws_session_token=IQoJb3JpZ2luX2VjEAsaCXVzLXdlc3QtMiJHMEUCIGRucAtge3zx8yjjhB74HnBipQ6otLV1lqsYQqL+KO1JAiEA3J0muf9wyuDghJO6uJf0AI/qiA0l732OmvW5dbkJzcwquQIItP//////////ARABGgwwNjA1MDQ3OTg1ODMiDJ4Oz08UkPeFTKRFlSqNAtVwziBWTXTc0hk/AXw47qucrOEECAcLtGg+L4L3z/t7rceTcA37pz0kMUf/CNppLeVHaeU+uJjf8t+idyL1nJJtDIK1mIy9vMkTFbnFsInPrOaCFZI16BXCGBpE1p4U0t2ns+EpQ5/mWiILXg16647gkFM/SgtMEOKllDV8QXrLNSHCnC97Rrig+zSuyZntbO2rK6Iz7Me2jesi2lxI64W9WtTEADBZrIo6Yw31/cOyk//z5JHyyos4Hm82OpDqu0pAhfMs04d8+/D/rhpG/tC7PAFEA1FpfmvizbdJ+x7FzbdU9sjpgt67uxqYkqPI5QP12t77o42g7GtjQJZDUDyKtUKuB7EzQGr60QbvMJ26tLoGOp0BBG1PuI6VbDGMxaEqiaWAZj/iCXW/0NOprAsLiwcXctU4Sx0cZhyL1Ent9gWsodkm/6CKpouMw0oYnzhi13QRUu8l5ymbl3dCMfJZGYBe6k30JZJtZGEFR8ulRVpF3xKzX1BXd5pnwHTLBizZNvx4CpRthc8AdOAYSb/OYzVGjW5lar9SifPEFZrj1dWpM6XKPxRx5Dg6joWkyMdqZA=="
      ],
      "metadata": {
        "id": "7IbaOU8MQfZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "\n",
        "def download_from_s3_with_temp_credentials(bucket_name, file_key, aws_access_key_id, aws_secret_access_key, aws_session_token):\n",
        "\n",
        "    # Crear un cliente de S3 con credenciales temporales\n",
        "    s3 = boto3.client(\n",
        "        \"s3\",\n",
        "        aws_access_key_id=aws_access_key_id,\n",
        "        aws_secret_access_key=aws_secret_access_key,\n",
        "        aws_session_token=aws_session_token,\n",
        "    )\n",
        "    try:\n",
        "        # Descargar el archivo desde S3\n",
        "        response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
        "\n",
        "        # Leer el contenido del archivo Excel como DataFrame\n",
        "        df = pd.read_excel(BytesIO(response[\"Body\"].read()), engine=\"openpyxl\")\n",
        "        print(f\"Archivo {file_key} descargado exitosamente.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error al descargar el archivo: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Configuración\n",
        "BUCKET_NAME = \"proyectointegrador\"\n",
        "FILE_KEY_TO_DOWNLOAD = \"zona_raw/dataset_estancia_hospitalaria.xlsx\"  # Cambia la extensión a .xlsx\n",
        "\n",
        "# Credenciales temporales\n",
        "AWS_ACCESS_KEY_ID = \"ASIAQ4FS56V3QHBQZA6P\"\n",
        "AWS_SECRET_ACCESS_KEY = \"COPSG9Q3CLAkz/dsOgH93ghVNpNroyX7ptLGx0g2\"\n",
        "AWS_SESSION_TOKEN = \"IQoJb3JpZ2luX2VjEAsaCXVzLXdlc3QtMiJHMEUCIGRucAtge3zx8yjjhB74HnBipQ6otLV1lqsYQqL+KO1JAiEA3J0muf9wyuDghJO6uJf0AI/qiA0l732OmvW5dbkJzcwquQIItP//////////ARABGgwwNjA1MDQ3OTg1ODMiDJ4Oz08UkPeFTKRFlSqNAtVwziBWTXTc0hk/AXw47qucrOEECAcLtGg+L4L3z/t7rceTcA37pz0kMUf/CNppLeVHaeU+uJjf8t+idyL1nJJtDIK1mIy9vMkTFbnFsInPrOaCFZI16BXCGBpE1p4U0t2ns+EpQ5/mWiILXg16647gkFM/SgtMEOKllDV8QXrLNSHCnC97Rrig+zSuyZntbO2rK6Iz7Me2jesi2lxI64W9WtTEADBZrIo6Yw31/cOyk//z5JHyyos4Hm82OpDqu0pAhfMs04d8+/D/rhpG/tC7PAFEA1FpfmvizbdJ+x7FzbdU9sjpgt67uxqYkqPI5QP12t77o42g7GtjQJZDUDyKtUKuB7EzQGr60QbvMJ26tLoGOp0BBG1PuI6VbDGMxaEqiaWAZj/iCXW/0NOprAsLiwcXctU4Sx0cZhyL1Ent9gWsodkm/6CKpouMw0oYnzhi13QRUu8l5ymbl3dCMfJZGYBe6k30JZJtZGEFR8ulRVpF3xKzX1BXd5pnwHTLBizZNvx4CpRthc8AdOAYSb/OYzVGjW5lar9SifPEFZrj1dWpM6XKPxRx5Dg6joWkyMdqZA==\"\n",
        "\n",
        "# Descargar el archivo desde S3\n",
        "data = download_from_s3_with_temp_credentials(\n",
        "    BUCKET_NAME,\n",
        "    FILE_KEY_TO_DOWNLOAD,\n",
        "    AWS_ACCESS_KEY_ID,\n",
        "    AWS_SECRET_ACCESS_KEY,\n",
        "    AWS_SESSION_TOKEN.strip()  # Elimina espacios en blanco adicionales\n",
        ")\n",
        "\n",
        "# Mostrar los datos descargados\n",
        "if data is not None:\n",
        "  data = data_.drop(['fecha', 'unidad_x_edad', 'año', 'mes'],axis=1)\n",
        "else:\n",
        "  print(\"No se pudo descargar el dataset desde S3\")\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "0SPdo_qjbK_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar el dataset desde archivo local"
      ],
      "metadata": {
        "id": "4gSDRdTibI9I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIzAcgLE4tPL"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('INSUMOS/dataset_estancia_hospitalaria.xlsx', index_col = None)\n",
        "#data['f_analisis'] = data['año']*100 + data['mes']\n",
        "data = data.drop(['fecha', 'unidad_x_edad', 'año', 'mes'],axis=1)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mhXZ5zz2yYE"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir las variables de modelación y respuesta"
      ],
      "metadata": {
        "id": "ipl8rcqlbE4v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3UOGnROoJGj"
      },
      "outputs": [],
      "source": [
        "feats_train = ['ir_cdm', 'ir_grd_base', 'nivel_de_complejidad',\n",
        "              'procedimiento_principal', 'diagnostico_principal', 'estancia_en_uci', 'edad',\n",
        "              'costo_operativo_estimado', 'peso_ir_estimado']\n",
        "\n",
        "feat_target = 'estancia_total'\n",
        "\n",
        "print('Las variables de entrenamiento son',len(feats_train), ':')\n",
        "print(feats_train)\n",
        "\n",
        "print('\\nLa variable de respuesta es: ', feat_target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se remueven las columnas innecesarias para que el procesamiento sea más directo"
      ],
      "metadata": {
        "id": "eV-txi-axPId"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlSzw0-O6P3l"
      },
      "outputs": [],
      "source": [
        "data = data[feats_train + [feat_target]]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PBv9iTNtVTN"
      },
      "source": [
        "### Separar variables categóricas y numericas para facilitar el análisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFgeDwYV9upu"
      },
      "outputs": [],
      "source": [
        "feats_categoricas = data[feats_train].select_dtypes(include=['object']).columns\n",
        "feats_numericas = data[feats_train].select_dtypes(include=['number']).columns\n",
        "print('Variables categoricas: ', list(feats_categoricas))\n",
        "print('\\nVariables numericas: ', list(feats_numericas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGg5NMEM8SwF"
      },
      "outputs": [],
      "source": [
        "data[feats_numericas].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTf3DpOk6NO1"
      },
      "outputs": [],
      "source": [
        "data[list(feats_numericas) + [feat_target]].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QpvP8U-_4yJ"
      },
      "source": [
        "### Remover texto no informativo de las variables categoricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhIQnNzEAs-2"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "\n",
        "def remover_texto_no_informativo(text):\n",
        "    return re.sub(r'^.*? -', '', text)\n",
        "\n",
        "\n",
        "def remover_tildes_y_simbolos(text):\n",
        "    # Normalize the input string into a decomposed form (NFD)\n",
        "    nfkd_form = unicodedata.normalize('NFD', text)\n",
        "    # Remove characters that are non-spacing marks (diacritical marks)\n",
        "    return ''.join([char for char in nfkd_form if unicodedata.category(char) != 'Mn'])\n",
        "\n",
        "def remover_espacios_y_minusculas(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip().lower()\n",
        "\n",
        "for f in feats_categoricas:\n",
        "  data[f] = data[f].apply(remover_texto_no_informativo)\n",
        "  data[f] = data[f].apply(remover_tildes_y_simbolos)\n",
        "  data[f] = data[f].apply(remover_espacios_y_minusculas)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "id": "ncQzZjTbf7RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvcA1pfDqD5w"
      },
      "source": [
        "### Validar registros nulos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlIby2ApX4kS"
      },
      "source": [
        "Hay una limitación en numpy para reconocer string vacias como un dato nulo(NaN) por lo que toca remover estas filas manualmente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AgAv1GfVX7V"
      },
      "outputs": [],
      "source": [
        "data = data[(data['ir_cdm'] != '')\n",
        "            & (data['ir_grd_base'] != '')\n",
        "            & (data['nivel_de_complejidad'] != '')\n",
        "            & (data['procedimiento_principal'] != '')\n",
        "            & (data['diagnostico_principal'] != '')]\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJce6tillV0q"
      },
      "outputs": [],
      "source": [
        "data = data.reset_index(drop=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-B1--Zl4wKl"
      },
      "source": [
        "### Validar registros duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aruiKst4sFl"
      },
      "outputs": [],
      "source": [
        "# Revisar valores duplicados en el dataset\n",
        "filas_duplicadas = data.duplicated().sum()\n",
        "print(f'# de registros duplicados: {filas_duplicadas}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ETAPA 2 - ANÁLISIS EXPLORATORIO DE DATOS**\n",
        "\n",
        "Con el dataset depurado se avalizan las variables para entender mejor el comportamiento esperado durante el entrenamiento y los resultados obtenidos del proceso. En la etapa de exploración se busca hacer un análisis estadístico descriptivo de todas las variables disponibles, desde un enfoque univariado (completitud, tendencia central, significancia, distribución) y multivariado (Correlación total y parcial, variabilidad, explicabilidad).\n",
        "\n",
        "**Pasos realizados**\n",
        "\n",
        "- Visualización inicial\n",
        "  - Scatter plot en relación con la variable de respuesta\n",
        "  - Boxplot e histogramas de distribución  \n",
        "- Estadísticos y gráficas descriptivas complementarias\n",
        "  - Análisis de frecuencias\n",
        "  - Medidas de tendencia y dispersión\n",
        "  - Pruebas de normalidad\n",
        "  - Funciones de densidad y normalidad\n",
        "- Correlaciones\n",
        "\n",
        "**Resultado final**\n",
        "\n",
        "Comprensión de los datos disponibles e insights para la transformación de características\n"
      ],
      "metadata": {
        "id": "G60C6_7ek3mE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feats numéricas**"
      ],
      "metadata": {
        "id": "D_dZcA7joQVp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zol8HXA09MDm"
      },
      "source": [
        "### Boxplot e histogramas interactivos iniciales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdfoiqvZ8nAd"
      },
      "outputs": [],
      "source": [
        "for f in feats_numericas:\n",
        "  df = data.groupby([f]).agg(conteo=(feat_target, 'count')).reset_index()\n",
        "  df['perc'] = round((df['conteo'] / df['conteo'].sum())*100, 1)\n",
        "  df = df.sort_values(by='perc', ascending=False)\n",
        "  fig = px.histogram(df, x = f, y = 'conteo', text_auto=True, title = f)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLdWtJfL620V"
      },
      "outputs": [],
      "source": [
        "for f in feats_numericas:\n",
        "  fig = px.box(data, y=f, width=600, height=400)\n",
        "  fig.update_layout(title_text = f)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relación con la variable de respuesta"
      ],
      "metadata": {
        "id": "NYDlomqJxUHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO18uLVUso2P"
      },
      "outputs": [],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "fig = make_subplots(rows=2, cols=2)\n",
        "\n",
        "for f in feats_numericas:\n",
        "  fig = px.scatter(data, x = f, y = feat_target, trendline=\"ols\", width=600, height=400)\n",
        "  fig.update_layout(title_text = f)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estadísticos y descriptivas"
      ],
      "metadata": {
        "id": "eg5nSd9k2Ebk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for f in feats_numericas:\n",
        "  print('\\n\\t\\t',str.upper(f), '\\n')\n",
        "  fu.inter_uncond_descrp_num_var(f, col = data[f])"
      ],
      "metadata": {
        "id": "JhNQHmEyk2wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlaciones"
      ],
      "metadata": {
        "id": "w02jQX1l2P3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feats = list(feats_numericas) + [feat_target]\n",
        "fu.print_corr_var(data[feats])"
      ],
      "metadata": {
        "id": "7Xl4OpvAww-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feats categóricas**"
      ],
      "metadata": {
        "id": "Fc8U7pMCoGdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test ANOVA de significancia sobre la relación con la variable de respuesta"
      ],
      "metadata": {
        "id": "NNb3oJ9uwMlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "for f in feats_categoricas:\n",
        "  categories = data[f].unique()\n",
        "  groups = [data[data[f] == category][feat_target] for category in categories]\n",
        "\n",
        "  f_stat, p_value = f_oneway(*groups)\n",
        "  print(f\"\\nANOVA p-value de la variable {f}: {p_value}\")"
      ],
      "metadata": {
        "id": "ySYEwugDwMMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como las p-values son significativos (p < 0.05), se infiere que hay relación entre las variables categoricas y la de respuesta"
      ],
      "metadata": {
        "id": "caSic1aV5nYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Promedio de target por categoria"
      ],
      "metadata": {
        "id": "-mQD53v850_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for f in feats_categoricas:\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  sns.barplot(x=f, y=feat_target, data=data, ci=None)\n",
        "  plt.title(f'Promedio de target por categoria de {f}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "fhB782By52AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estadísticos y descriptivas"
      ],
      "metadata": {
        "id": "v0UFyx9nw0x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for f in feats_categoricas:\n",
        "  print('\\n\\t\\t',str.upper(f), '\\n')\n",
        "  fu.inter_uncond_descrp_cat_var(f, col = data[f])"
      ],
      "metadata": {
        "id": "gkDtLOjkoLnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feat target**"
      ],
      "metadata": {
        "id": "moFNEaMKxrpK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wULKEmF27HHd"
      },
      "outputs": [],
      "source": [
        "fig = px.box(data, y=feat_target, width=600, height=400)\n",
        "fig.update_layout(title_text = feat_target)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNuMnpbv0oxI"
      },
      "source": [
        "# **ETAPA 3 - FEATURE ENGINEERING**\n",
        "\n",
        "Una vez se han analizado las variables de modelación, se procede a realizar las transformaciones necesarias para reducir el sesgo durante el entrenamiento y generar confianza sobre la evaluación de los modelos obtenidos.\n",
        "\n",
        "**Pasos realizados**\n",
        "\n",
        "- Identificar outliers en variables numéricas\n",
        "  - Evaluar distancia de Mahalanobis\n",
        "  - Aplicar clustering DBSCAN  \n",
        "- Identificar outliers en variables categóricas\n",
        "  - Aplicar moda de variable a las categorias potenciales outliers\n",
        "  - Aplicar Multiple Corresponde Analisys (MCA)\n",
        "  - Evaluar distancia de Hamming\n",
        "- Consolidar y remover outliers del dataset\n",
        "- Acotar (Winsorizing) variable de respuesta para mitigar sesgos por outliers\n",
        "\n",
        "**Resultado final**\n",
        "\n",
        "Dataset sin outliers para modelación\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import DBSCAN\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "D45Rt0wGCbJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byGxhdxD3JUY"
      },
      "source": [
        "## 3.1 Identificar outliers de feats numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfKjDNudJPvb"
      },
      "outputs": [],
      "source": [
        "data_numerica = data[feats_numericas]\n",
        "print(data_numerica.shape)\n",
        "data_numerica.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smpxSBiG3Pz7"
      },
      "source": [
        "### **Distancia de Mahalanobis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tugQj1FOYVpp"
      },
      "outputs": [],
      "source": [
        "data_numerica.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BxU0l3ZJMNq"
      },
      "outputs": [],
      "source": [
        "data_numerica = data_numerica.values\n",
        "scaler = RobustScaler()\n",
        "data_numerica_std = scaler.fit_transform(data_numerica)\n",
        "data_numerica_std.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl3hXnkISq7F"
      },
      "outputs": [],
      "source": [
        "punto_central = np.mean(data_numerica_std, axis=0)\n",
        "punto_central"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(data_numerica_std)"
      ],
      "metadata": {
        "id": "U8Y1E_1M99F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX5YPxjZ3I7H"
      },
      "outputs": [],
      "source": [
        "matriz_covarianza  = np.cov(data_numerica_std, rowvar=False)\n",
        "matriz_covarianza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIaxazPi3I05"
      },
      "outputs": [],
      "source": [
        "covarianza_inversa = np.linalg.inv(matriz_covarianza)\n",
        "covarianza_inversa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFVU_VU6DOO4"
      },
      "outputs": [],
      "source": [
        "mahalanobis = []\n",
        "\n",
        "for i, x in enumerate(data_numerica_std):\n",
        "  distancia = (x - punto_central).T.dot(covarianza_inversa).dot(x - punto_central)\n",
        "  mahalanobis.append(distancia)\n",
        "mahalanobis = np.array(mahalanobis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpsW_dXNDOMy"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import chi2\n",
        "\n",
        "corte = chi2.ppf(0.95, data_numerica_std.shape[1])\n",
        "\n",
        "outliers_feats_num_mahalanobis = np.where(mahalanobis > corte )[0]\n",
        "\n",
        "print('Index de outliers de variables numericas')\n",
        "print(outliers_feats_num_mahalanobis)\n",
        "\n",
        "#print(data_numerica[mahalanobis > corte , :])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm-cfQ9KG0ET"
      },
      "outputs": [],
      "source": [
        "corte"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outliers = mahalanobis > np.sqrt(corte)\n",
        "outliers"
      ],
      "metadata": {
        "id": "bIkzbisn9Wt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx17kZo_DOKp"
      },
      "outputs": [],
      "source": [
        "len(outliers_feats_num_mahalanobis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjXmG3k7Gdyu"
      },
      "outputs": [],
      "source": [
        "mahalanobis[outliers_feats_num_mahalanobis]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_result[0]"
      ],
      "metadata": {
        "id": "I1-A7Pzj-ehR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=outliers, cmap='coolwarm', marker='o')\n",
        "plt.title(\"Distancia de Mahalanobis con PCA\", fontsize=16)\n",
        "plt.xlabel('Componente 1')\n",
        "plt.ylabel('Componente 2')\n",
        "plt.colorbar(label=\"Outliers\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UBHJGoeL8880"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlDU_wnFCuPj"
      },
      "source": [
        "### **DBSCAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhSc-0uuCsyb"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(data[feats_numericas])\n",
        "df_scaled = pd.DataFrame(df_scaled, columns=feats_numericas)\n",
        "df_scaled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GC9Hbh2Kv0F"
      },
      "outputs": [],
      "source": [
        "neighbors = NearestNeighbors(n_neighbors=5)\n",
        "neighbors_fit = neighbors.fit(df_scaled)\n",
        "distances, indices = neighbors_fit.kneighbors(df_scaled)\n",
        "\n",
        "sorted_distances = np.sort(distances[:, -1], axis=0)\n",
        "\n",
        "df_k = pd.DataFrame(sorted_distances).reset_index()\n",
        "df_k.columns = ['registros', 'distancias']\n",
        "\n",
        "fig = px.line(df_k, x=\"registros\", y=\"distancias\", title=\"Distancias al 5° vecino más cercano\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De la gráfica anterior se infiere que el codo se presenta cuando k=1"
      ],
      "metadata": {
        "id": "vxrCAU6yAhlw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuqtowA_Ct8Z"
      },
      "outputs": [],
      "source": [
        "dbscan = DBSCAN(eps=1, min_samples=5, n_jobs=-1)\n",
        "df_scaled['Outlier'] = dbscan.fit_predict(df_scaled)\n",
        "\n",
        "df_scaled['Outlier'] = df_scaled['Outlier'] == -1\n",
        "df_scaled.groupby('Outlier')['edad'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhCJ5I7wLqqy"
      },
      "outputs": [],
      "source": [
        "# Reduce the data to 2D using PCA for visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(df_scaled)\n",
        "\n",
        "outliers = df_scaled[df_scaled['Outlier'] == True]\n",
        "\n",
        "# Add the PCA components to the dataframe\n",
        "df_scaled['PCA1'] = X_pca[:, 0]\n",
        "df_scaled['PCA2'] = X_pca[:, 1]\n",
        "\n",
        "fig = px.scatter(df_scaled, x='PCA1', y='PCA2', color='Outlier',\n",
        "                 title='DBSCAN Clustering (Proyección PCA )',\n",
        "                 labels={'PCA1': 'PCA Componente 1', 'PCA2': 'PCA Componente 2'},\n",
        "                 color_continuous_scale='Viridis',\n",
        "                 category_orders={'Cluster': [-1, 0, 1, 2]},\n",
        "                )\n",
        "\n",
        "# Add hover information (e.g., point index and cluster label)\n",
        "fig.update_traces(marker=dict(size=5), hoverinfo='x+y+text',\n",
        "                  hovertext=df_scaled.index.astype(str) + '<br>Cluster: ' + df_scaled['Outlier'].astype(str))\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYiyFYYSIcyX"
      },
      "outputs": [],
      "source": [
        "df = df_scaled.loc[df_scaled.Outlier == True].reset_index()\n",
        "outliers_feats_num_dbscan = list(df['index'])\n",
        "print(len(outliers_feats_num_dbscan))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se valida la correcta aplicación de DBSCAN con el score Silhouette que evidencia una buena separación de grupos de datos para facilitar la identificación de outliers"
      ],
      "metadata": {
        "id": "gJGqly-UYYmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette = silhouette_score(df_scaled, df_scaled['Outlier'])\n",
        "db_index = davies_bouldin_score(df_scaled, df_scaled['Outlier'])\n",
        "\n",
        "print(\"Resultados de DBSCAN:\")\n",
        "print(f\"Coeficiente de Silueta: {silhouette}\")\n",
        "print(f\"Índice de Davies-Bouldin: {db_index}\\n\")"
      ],
      "metadata": {
        "id": "J2BzFAtoFFUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_ciLpyczLn1"
      },
      "source": [
        "## 3.2 Identificar outliers de feats categóricas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for f in feats_categoricas:\n",
        "  categories = data[f].unique()\n",
        "  print('La variable',f,'tiene categorias distintas:', len(categories))"
      ],
      "metadata": {
        "id": "SilLGWmiskJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Reemplazando moda en categorías con poca frecuencia**"
      ],
      "metadata": {
        "id": "aacll-ZH99ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reemplazar_categorias_poca_frecuencia(df, feats_agrupar, threshold=1):\n",
        "    for f in feats_agrupar:\n",
        "        conteos_categorias = df[f].value_counts()\n",
        "        moda = conteos_categorias.idxmax()\n",
        "        #top5 = conteos_categorias.head(5)\n",
        "        categorias_outliers = conteos_categorias[conteos_categorias <= threshold].index\n",
        "        #df[f] = df[f].apply(lambda x: top5.sample(1).idxmax() if x in categorias_outliers else x)\n",
        "        df[f] = df[f].apply(lambda x: moda if x in categorias_outliers else x)\n",
        "\n",
        "    return df\n",
        "\n",
        "feats_agrupar = ['ir_grd_base','procedimiento_principal', 'diagnostico_principal']\n",
        "data = reemplazar_categorias_poca_frecuencia(data, feats_agrupar, threshold=3)"
      ],
      "metadata": {
        "id": "RddSINSxAenG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f in feats_categoricas:\n",
        "  categories = data[f].unique()\n",
        "  print('La variable',f,'tiene categorias distintas:', len(categories))"
      ],
      "metadata": {
        "id": "sJEDtcis0MNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_categorica = data[feats_categoricas]\n",
        "print(data_categorica.shape)\n",
        "data_categorica.head()"
      ],
      "metadata": {
        "id": "7g0XNMOwIfXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5Ugh7CyTQYE"
      },
      "source": [
        "### **Multiple Correspondence Analysis (MCA)** - Feats categóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7RVszUpP8WB"
      },
      "source": [
        "#### **MCA con One-Hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp2B5s_5nJ_J"
      },
      "outputs": [],
      "source": [
        "oh_data_cat = pd.get_dummies(data_categorica)\n",
        "oh_data_cat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWy8YURqTCMp"
      },
      "outputs": [],
      "source": [
        "import prince\n",
        "\n",
        "mca = prince.MCA(\n",
        "    n_components=2,\n",
        "    n_iter=3,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='sklearn',\n",
        "    random_state=42,\n",
        "    one_hot=False\n",
        ")\n",
        "\n",
        "mca = mca.fit(oh_data_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20xpMkeqTCIR"
      },
      "outputs": [],
      "source": [
        "mca.eigenvalues_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ-iwRyTnzZn"
      },
      "outputs": [],
      "source": [
        "mca_coordenadas = mca.transform(oh_data_cat)\n",
        "print(mca_coordenadas.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se valida la correcta aplicación de MCA con el score Silhouette que evidencia una buena separación de grupos de datos para facilitar la identificación de outliers"
      ],
      "metadata": {
        "id": "0c6IkbAHYJwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=3)\n",
        "clusters = kmeans.fit_predict(mca_coordenadas)\n",
        "\n",
        "silhouette = silhouette_score(mca_coordenadas, clusters)\n",
        "print(f\"Silhouette Score: {silhouette}\")"
      ],
      "metadata": {
        "id": "l7lZXQbtJF3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ325isQoPGq"
      },
      "outputs": [],
      "source": [
        "centroide = mca_coordenadas.mean(axis=0)\n",
        "\n",
        "distancias = cdist(mca_coordenadas, [centroide], metric='euclidean')\n",
        "corte = np.mean(distancias) + 2 * np.std(distancias)\n",
        "outliers_feats_cat_OH = np.where(distancias > corte)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iLVcUZ2Mq2P"
      },
      "outputs": [],
      "source": [
        "df_mca = list(zip(mca_coordenadas.iloc[:, 0], mca_coordenadas.iloc[:, 1], distancias[:, 0]))\n",
        "df_mca = pd.DataFrame(df_mca, columns = [0,1,'distancia'])\n",
        "df_mca.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5ophv5bIzx7"
      },
      "outputs": [],
      "source": [
        "def plot_PC_outliers(df_mca, outliers, x, y):\n",
        "  fig = make_subplots()\n",
        "  fig.add_trace(\n",
        "      px.scatter(df_mca, x = x, y = y, hover_data = ['distancia']).data[0]\n",
        "  )\n",
        "  fig['data'][0]['showlegend']=True\n",
        "  fig['data'][0]['name']='Aceptados'\n",
        "\n",
        "  fig.add_trace(\n",
        "      px.scatter(df_mca.iloc[outliers[:]], x = x, y = y, hover_data = ['distancia'], color_discrete_sequence=['red']).data[0]\n",
        "  )\n",
        "  fig['data'][1]['showlegend']=True\n",
        "  fig['data'][1]['name']='Outliers'\n",
        "\n",
        "  fig.update_layout(title_text = f'PC{x} vs PC{y}')\n",
        "\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5sZJrp3Isfy"
      },
      "outputs": [],
      "source": [
        "plot_PC_outliers(df_mca, outliers_feats_cat_OH, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OpqsdXSSFTj"
      },
      "source": [
        "#### **MCA con factorización**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf3oD8aeTn2V"
      },
      "outputs": [],
      "source": [
        "factorized_data_cat = data_categorica.apply(lambda col: pd.factorize(col)[0])\n",
        "factorized_data_cat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV4pdKczbyHH"
      },
      "source": [
        "Se suma 1 al encoding para garantizar la división al momento de ajustar MCA. Esto no afecta el resultado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjKzPbW5Tz6z"
      },
      "outputs": [],
      "source": [
        "factorized_data_cat = factorized_data_cat + 1\n",
        "factorized_data_cat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgW0NuDU3Iyl"
      },
      "outputs": [],
      "source": [
        "import prince\n",
        "\n",
        "mca = prince.MCA(\n",
        "    n_components=2,\n",
        "    n_iter=10,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='sklearn',\n",
        "    random_state=42,\n",
        "    one_hot=False\n",
        ")\n",
        "\n",
        "mca = mca.fit(factorized_data_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eOkY6HgSEvk"
      },
      "outputs": [],
      "source": [
        "mca.eigenvalues_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfbJPXUPUy-l"
      },
      "outputs": [],
      "source": [
        "mca_coordenadas = mca.transform(factorized_data_cat)\n",
        "print(mca_coordenadas.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se valida la correcta aplicación de MCA con el score Silhouette que evidencia una buena separación de grupos de datos para facilitar la identificación de outliers"
      ],
      "metadata": {
        "id": "HhNubph8YWtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "clusters = kmeans.fit_predict(mca_coordenadas)\n",
        "\n",
        "silhouette = silhouette_score(mca_coordenadas, clusters)\n",
        "print(f\"Silhouette Score: {silhouette}\")"
      ],
      "metadata": {
        "id": "b_oKEdkrJ4eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idPii6IRUy-m"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "centroide = mca_coordenadas.mean(axis=0)\n",
        "\n",
        "distancias = cdist(mca_coordenadas, [centroide], metric='euclidean')\n",
        "corte = np.mean(distancias) + (3 * np.std(distancias)) # Regla 3-sigma que cubre el 99% de la distribución\n",
        "outliers_feats_cat_fact = np.where(distancias > corte)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6yBGjtGV_kb"
      },
      "outputs": [],
      "source": [
        "corte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TY7CWVRU6hc"
      },
      "outputs": [],
      "source": [
        "len(outliers_feats_cat_fact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAjqRPcOUy-m"
      },
      "outputs": [],
      "source": [
        "df_mca = list(zip(mca_coordenadas.iloc[:, 0], mca_coordenadas.iloc[:, 1], distancias[:, 0]))\n",
        "df_mca = pd.DataFrame(df_mca, columns = [0,1, 'distancia'])\n",
        "df_mca.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2iukYY_Uy-m"
      },
      "outputs": [],
      "source": [
        "plot_PC_outliers(df_mca, outliers_feats_cat_fact, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4SXYLHUn8f"
      },
      "source": [
        "### **DBSCAN - Distancia de Hamming**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_categorica.info(verbose=True)"
      ],
      "metadata": {
        "id": "06oMCeJN7g6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = data_categorica.apply(lambda col: col.astype('category').cat.codes)\n",
        "df_encoded.shape"
      ],
      "metadata": {
        "id": "2RoSBJZr4Lr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fvGJl2-VDIz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "# Compute pairwise Hamming distance for categorical data\n",
        "#distances = pairwise_distances(df_encoded, metric='hamming', n_jobs=-1)\n",
        "\n",
        "# Apply DBSCAN to the distance matrix\n",
        "#db = DBSCAN(eps=0.2, min_samples=2, metric='precomputed')\n",
        "#df_encoded['Outlier'] = db.fit_predict(distances)\n",
        "\n",
        "#df_encoded['Outlier'] = df_encoded['Outlier'] == -1\n",
        "#df_encoded['Outlier'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt5FJsQYVDGG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKDoK5VHVDDi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PV04n2oJ-EaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8SKdus-i4-r"
      },
      "source": [
        "## 3.3 Remover outliers calculados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rjB-wVfFucA"
      },
      "source": [
        "### **Cargar indices de outliers calculados previamente**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrOdOg40q7MA"
      },
      "outputs": [],
      "source": [
        "outliers_feats_num_mahalanobis = pd.read_csv('INDICES_OUTLIERS/outliers_feats_num_mahalanobis.csv')\n",
        "outliers_feats_num_mahalanobis = outliers_feats_num_mahalanobis.to_numpy()\n",
        "outliers_feats_num_mahalanobis = outliers_feats_num_mahalanobis.flatten()\n",
        "\n",
        "outliers_feats_num_dbscan = pd.read_csv('INDICES_OUTLIERS/outliers_feats_num_dbscan.csv')\n",
        "outliers_feats_num_dbscan = outliers_feats_num_dbscan.to_numpy()\n",
        "outliers_feats_num_dbscan = outliers_feats_num_dbscan.flatten()\n",
        "\n",
        "outliers_feats_cat_fact = pd.read_csv('INDICES_OUTLIERS/outliers_feats_cat_fact.csv')\n",
        "outliers_feats_cat_fact = outliers_feats_cat_fact.to_numpy()\n",
        "outliers_feats_cat_fact = outliers_feats_cat_fact.flatten()\n",
        "\n",
        "outliers_feats_cat_OH = pd.read_csv('INDICES_OUTLIERS/outliers_feats_cat_OH.csv')\n",
        "outliers_feats_cat_OH = outliers_feats_cat_OH.to_numpy()\n",
        "outliers_feats_cat_OH = outliers_feats_cat_OH.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts39m8dNFyY2"
      },
      "source": [
        "### Consolidar y exportar indices de outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu_xx12kjlc8"
      },
      "outputs": [],
      "source": [
        "print('Outliers de variables numéricas - Mahalanobis:', len(outliers_feats_num_mahalanobis))\n",
        "\n",
        "print('\\nOutliers de variables numéricas - DBSCAN:', len(outliers_feats_num_dbscan))\n",
        "\n",
        "print('\\nOutliers de variables categóricas - One Hot:', len(outliers_feats_cat_OH))\n",
        "\n",
        "print('\\nOutliers de variables categóricas - Factorización:', len(outliers_feats_cat_fact))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6nZTCrfi4ct"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "\n",
        "outliers = list(chain(outliers_feats_num_dbscan, outliers_feats_cat_fact, outliers_feats_cat_OH))\n",
        "outliers = list(set(outliers))\n",
        "data_sin_outliers = data.drop(data.index[outliers])\n",
        "print('\\nCantidad de oultiers total removidos:', len(outliers))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perc = 1 - data_sin_outliers.shape[0] / data.shape[0]\n",
        "print(\"\\nRegistros del dataset inicial: \", data.shape[0])\n",
        "print(\"\\nRegistros del dataset sin outliers: \", data_sin_outliers.shape[0])\n",
        "print(\"\\nPorcentaje de datos removidos como outliers: \"+\"{:.1%}\".format(perc))"
      ],
      "metadata": {
        "id": "Ka3HDmjy1tpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHTbqlnBq90s"
      },
      "source": [
        "### Validar aplicación adecuada de outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NYqaRzKmnfUU"
      },
      "outputs": [],
      "source": [
        "for f in feats_numericas:\n",
        "  fig = px.box(data_sin_outliers, y=f, width=600, height=400)\n",
        "  fig.update_layout(title_text = f)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Acotar variable de respuesta por encima de percentil 99 (Winsorizing)"
      ],
      "metadata": {
        "id": "34V25Pp9UkGT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiJsYy2LFtrQ"
      },
      "outputs": [],
      "source": [
        "target_p99 = np.percentile(data_sin_outliers[feat_target], 99)\n",
        "data_sin_outliers[feat_target] = data_sin_outliers[feat_target].clip(upper=target_p99)\n",
        "data_sin_outliers.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_sin_outliers[feat_target].describe(percentiles=[.01, .1, .2, .25, .4, .5, .75, .9, .95, .99])"
      ],
      "metadata": {
        "id": "vTuijT92eSTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejecutar UNICAMENTE cuando se actualicen los outliers para exportar a CSV"
      ],
      "metadata": {
        "id": "0f9WXMOQcjTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir INDICES_OUTLIERS\n",
        "\n",
        "df = pd.DataFrame(data={\"indices\": outliers_feats_num_mahalanobis})\n",
        "df.to_csv(\"INDICES_OUTLIERS/outliers_feats_num_mahalanobis.csv\", sep=',',index=False)\n",
        "\n",
        "df = pd.DataFrame(data={\"indices\": outliers_feats_num_dbscan})\n",
        "df.to_csv(\"INDICES_OUTLIERS/outliers_feats_num_dbscan.csv\", sep=',',index=False)\n",
        "\n",
        "df = pd.DataFrame(data={\"indices\": outliers_feats_cat_OH})\n",
        "df.to_csv(\"INDICES_OUTLIERS/outliers_feats_cat_OH.csv\", sep=',',index=False)\n",
        "\n",
        "df = pd.DataFrame(data={\"indices\": outliers_feats_cat_fact})\n",
        "df.to_csv(\"INDICES_OUTLIERS/outliers_feats_cat_fact.csv\", sep=',',index=False)"
      ],
      "metadata": {
        "id": "8sBawBbJcL1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTUnw2ds1S40"
      },
      "source": [
        "# **ETAPA 4 - PREPARACIÓN DE LOS DATOS DE MODELACIÓN**\n",
        "\n",
        "Con el dataset depurado de outliers se puede proceder a la preparación final de datos para el proceso de modelación.\n",
        "\n",
        "**Pasos realizados**\n",
        "\n",
        "- Particionar el dataset en conjuntos de train y test\n",
        "- Aplicar target encoding regularizado a las variables categóricas\n",
        "- Estandarizar los datos codificados para reducir la varianza de entrenamiento\n",
        "- Validar multicolinearidad del dataset final de entrenamiento\n",
        "\n",
        "**Resultado final**\n",
        "\n",
        "Dataset listo para modelar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA3bqDMY1avV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import category_encoders as ce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW-yQtJgra5I"
      },
      "source": [
        "## 4.1 Particionar, codificar y estandarizar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqZ8NiY3sggg"
      },
      "outputs": [],
      "source": [
        "feats_train = list(data_sin_outliers.columns)\n",
        "feats_train.remove(feat_target)\n",
        "feats_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir variables dependientes e independientes\n",
        "X = data_sin_outliers[feats_train]\n",
        "y = data_sin_outliers[feat_target]\n",
        "\n",
        "#Generar particiones\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                  y,\n",
        "                                                  test_size=0.1,\n",
        "                                                  stratify=y,\n",
        "                                                  random_state=42)\n",
        "\n",
        "perc_train = X_train.shape[0] / data_sin_outliers.shape[0]\n",
        "print(\"Porcentaje de datos en partición train: \"+\"{:.1%}\".format(perc_train)+\" - registros: \"+str(X_train.shape[0]))\n",
        "\n",
        "perc_test = X_test.shape[0] / data_sin_outliers.shape[0]\n",
        "print(\"Porcentaje de datos en partición test: \"+\"{:.1%}\".format(perc_test)+\" - registros: \"+str(X_test.shape[0]))\n",
        "\n",
        "# Codificar variables categoricas de entrenamiento\n",
        "smoothing = 1\n",
        "encoder = ce.TargetEncoder(cols=list(feats_categoricas), smoothing=smoothing)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "\n",
        "# Estandarizar datos de entrenamiento\n",
        "scaler = StandardScaler()\n",
        "#scaler = MinMaxScaler()\n",
        "#scaler = RobustScaler()\n",
        "X_train_std = scaler.fit_transform(X_train_encoded[feats_train])\n",
        "X_test_std = scaler.transform(X_test_encoded[feats_train])"
      ],
      "metadata": {
        "id": "W1MVXvWtEzR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = X_test\n",
        "null_mask = df.isnull().any(axis=1)\n",
        "null_rows = df[null_mask]\n",
        "null_rows"
      ],
      "metadata": {
        "id": "hMBShp4vYlJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OozTjk5S-Pfq"
      },
      "source": [
        "## 4.2 Validar multicolinearidad en data de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGx37MkXirdS"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X_train[feats_train].columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_std, i) for i in range(X_train_std.shape[1])]\n",
        "\n",
        "vif_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR_FMSjgppr_"
      },
      "source": [
        "# **ETAPA 5 - TORNEO DE SELECCIÓN DE MODELOS**\n",
        "\n",
        "En este punto, antes de iniciar el proceso de ajuste de mejor modelo, se realizan torneos de selección de modelos para definir cuales tipos de regresión son las que ofrecen mejores resultados para la estimación de la estancia hospitalaria. Del mejor torneo resultante, se toma el top 3 de modelos para luego proceder al ajuste de hiperparámetros y así llegar al modelo final.\n",
        "\n",
        "**Pasos realizados**\n",
        "\n",
        "- Torneos de modelos variando configuraciones de:\n",
        "  - Tipos de outliers removidos\n",
        "  - Regularización del target encoding\n",
        "  - Tipo de estandarización de variables\n",
        "  - Aplicación de winsorizing\n",
        "\n",
        "\n",
        "**Resultado final**\n",
        "\n",
        "Modelos seleccionados para ajuste de hiperparámetros\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku-KqOLHEgH2"
      },
      "source": [
        "### Definir data final de entrenamiento para torneo de modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCRdFyIfNeMt"
      },
      "outputs": [],
      "source": [
        "data_train = pd.DataFrame(X_train_std, columns = feats_train)\n",
        "data_train[feat_target] = y_train.reset_index()[feat_target]\n",
        "data_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurar experimentos en el módulo de regresión de PyCaret"
      ],
      "metadata": {
        "id": "zuH_zcrlGRuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M90mGIZqEdt1"
      },
      "outputs": [],
      "source": [
        "from pycaret.regression import *\n",
        "\n",
        "setup(\n",
        "    data=data_train,\n",
        "    target=feat_target,\n",
        "    train_size=0.95,\n",
        "    normalize=False,\n",
        "    fold=10,\n",
        "    n_jobs=-1,\n",
        "    session_id=123\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUWMflCbcJC_"
      },
      "source": [
        "### **Torneo 1:** Removiendo sólo outliers de variables numéricas\n",
        "- Feats numéricas: DBSCAN\n",
        "- Estandarización: StandardScaler\n",
        "- Regularización target encoding: 0.5\n",
        "- Acotación de feat target: No\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh1KDN5BEdrf"
      },
      "outputs": [],
      "source": [
        "modelos=[\"lr\",\"rf\",\"knn\",\"lasso\",\"dt\",\"ridge\"]\n",
        "best = compare_models(include=modelos,n_select=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Torneo 2:** Removiendo outliers en todo el dataset\n",
        "- Feats numéricas: DBSCAN\n",
        "- Feats categoricas: MCA con factorización\n",
        "- Estandarización: StandardScaler\n",
        "- Regularización target encoding: 0.5\n",
        "- Acotación de feat target: Si\n"
      ],
      "metadata": {
        "id": "ALcCjtruTgFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelos=[\"lr\",\"rf\",\"knn\",\"lasso\",\"dt\",\"ridge\"]\n",
        "best = compare_models(include=modelos,n_select=2)"
      ],
      "metadata": {
        "id": "yrjjFlYMhP27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Torneo 3:** Removiendo outliers en todo el dataset - **Mejor torneo**\n",
        "\n",
        "- Feats numéricas: DBSCAN\n",
        "- Feats categoricas: MCA con factorización y One-Hot\n",
        "- Estandarización: StandardScaler\n",
        "- Regularización target encoding: 1\n",
        "- Acotación de feat target: Si\n"
      ],
      "metadata": {
        "id": "Sm7d_BFsf2bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelos=[\"lr\",\"rf\",\"knn\",\"lasso\",\"dt\",\"ridge\"]\n",
        "best = compare_models(include=modelos,n_select=1)"
      ],
      "metadata": {
        "id": "vo8aC15NtPVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Torneo 4:** Removiendo outliers en todo el dataset\n",
        "\n",
        "- Feats numéricas: Mahalanobis\n",
        "- Feats categoricas: MCA con factorización\n",
        "- Estandarización: StandardScaler\n",
        "- Regularización target encoding: 1\n",
        "- Acotación de feat target: Si"
      ],
      "metadata": {
        "id": "6kyKDjuSaujU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B44-iVyHEdnY"
      },
      "outputs": [],
      "source": [
        "modelos=[\"lr\",\"rf\",\"knn\",\"lasso\",\"dt\",\"ridge\"]\n",
        "best = compare_models(include=modelos,n_select=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Torneo 5:** Removiendo outliers en todo el dataset\n",
        "\n",
        "- Feats numéricas: DBSCAN\n",
        "- Feats categoricas: MCA con factorización\n",
        "- Estandarización: MinMaxScaler\n",
        "- Regularización target encoding: 1\n",
        "- Acotación de feat target: Si"
      ],
      "metadata": {
        "id": "LH1n9O2Gr-dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelos=[\"lr\",\"rf\",\"knn\",\"lasso\",\"dt\",\"ridge\"]\n",
        "best = compare_models(include=modelos,n_select=2)"
      ],
      "metadata": {
        "id": "j3xV6XmPr94z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Torneo 6:** Removiendo outliers en todo el dataset\n",
        "\n",
        "- Feats numéricas: Mahalanobis y DBSCAN\n",
        "- Feats categoricas: MCA con One-Hot y Factorización\n",
        "- Estandarización: StandardScaler\n",
        "- Regularización target encoding: 1\n",
        "- Acotación de feat target: Si"
      ],
      "metadata": {
        "id": "JDZ17O1IL4bi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Alwe4ZoEdjJ"
      },
      "outputs": [],
      "source": [
        "modelos=[\"lr\",\"rf\",\"knn\",\"lasso\",\"dt\",\"ridge\"]\n",
        "best = compare_models(include=modelos,n_select=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ETAPA 6 - ENTRENAMIENTO Y BÚSQUEDA DE HIPERPARÁMETROS DEL MEJOR MODELO**\n",
        "\n",
        "El proceso de ajuste de mejor modelo consta de entrenar los tipos de modelos seleccionados en la etapa anterior y a partir de los resultados de estimación y bondad de ajuste que muestre cada uno, finalmente seleccionar el mejor modelo para estimar la estancia hospitalaria.\n",
        "\n",
        "En cada tipo de modelo ajustado, se evalúan como métricas principales el $R^2$ y el $MAE$ que dan cuenta del ajuste adecuado a los datos de entrenamiento y el error en que se incurre al estimar la estancia hospitalaria con ese modelo. Cómo criterios adicionales, se dio prioridad a la interpretación de resultados y coherencia con la naturaleza de los datos analizado previamente en la etapa 2 (EDA).\n",
        "\n",
        "**Pasos realizados**\n",
        "\n",
        "- Ajuste de regresión lineal múltiple\n",
        "  - Mediante regresor de scikit-learn\n",
        "  - Mediante regresor de statsmodels OLS\n",
        "- Ajuste de regresión polinómica\n",
        "  - Mediante regresor de scikit-learn\n",
        "  - Mediante regresor de statsmodels OLS\n",
        "  - Prueba para distintos grados de polinomio\n",
        "- Ajuste de regresión KNN\n",
        "  - Prueba del codo para encontrar K-vecinos óptimo\n",
        "  - Búsqueda de hiperparámetros con malla y cross-validation\n",
        "  - Ajuste de mejor modelo encontrado con regresor de sickit-learn\n",
        "\n",
        "**Resultado final**\n",
        "\n",
        "Se opta por el modelo ajustado con KNN dado que sus métricas de varianza explicada y error estimado MAE. Si bien en el torneo de modelos, el regresor Random Forest fue el de mejores resultados, su capacidad para manejar relaciones no lineales y captar interacciones complejas entre variables lo convierte en una opción volátil dada la naturaleza no deterministica de los datos y el problema en general."
      ],
      "metadata": {
        "id": "-LBhuhIFUn_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.1 Regresión lineal**"
      ],
      "metadata": {
        "id": "Y3xBMYLrELZc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRm-0Bsc_i7C"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_std, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_2Lgqa8_wW2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test_std)\n",
        "\n",
        "mae_test = mae(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred, squared=True)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae_test}\")\n",
        "print(f\"RMSE: {mse}\")\n",
        "print(f\"R-squared: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrkOyjtJirYs"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X_train_std_ = sm.add_constant(X_train_std)\n",
        "model = sm.OLS(y_train,X_train_std_).fit()\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import jarque_bera\n",
        "\n",
        "# Step 2: Obtain residuals\n",
        "residuals = model.resid\n",
        "\n",
        "# Step 3: Perform the Jarque-Bera test\n",
        "jb_stat, jb_p_value = jarque_bera(residuals)\n",
        "\n",
        "# Step 4: Interpret the result\n",
        "print(f\"Jarque-Bera statistic: {jb_stat:.4f}\")\n",
        "print(f\"P-value: {jb_p_value:.4f}\")\n",
        "\n",
        "# Interpretation based on p-value:\n",
        "if jb_p_value < 0.05:\n",
        "    print(\"The residuals are likely not normally distributed (reject H₀).\")\n",
        "else:\n",
        "    print(\"The residuals are likely normally distributed (fail to reject H₀).\")"
      ],
      "metadata": {
        "id": "xUxjVsAnvjRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_std_ = sm.add_constant(X_test_std)\n",
        "y_pred = model.predict(X_test_std_)\n",
        "y_pred_train = model.predict(X_train_std_)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "mse = mean_squared_error(y_train, y_pred_train, squared=False)\n",
        "r2 = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(f\"RMSE: {mse}\")\n",
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "id": "PIt0Znk3uima"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.2 Regresión polinómica**"
      ],
      "metadata": {
        "id": "uiHNmG1SfMlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "X_train_poly = poly.fit_transform(X_train_std)\n",
        "X_test_poly = poly.transform(X_test_std)"
      ],
      "metadata": {
        "id": "_UhNtfphgv2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train_poly, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_poly)\n",
        "\n",
        "mae_test = mae(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R-squared: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "sNftEexLgv0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X_train_poly = sm.add_constant(X_train_poly)\n",
        "model = sm.OLS(y_train,X_train_poly).fit()\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "JyL3PCAugvyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicar búsqueda de hiperparámetros con Cross-Validation para obtener la regresión polinómica"
      ],
      "metadata": {
        "id": "Xb0WnTFkpaHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "\n",
        "degree = 3\n",
        "polyreg_pipeline = make_pipeline(\n",
        "    PolynomialFeatures(degree=degree),\n",
        "    LinearRegression()\n",
        ")\n",
        "\n",
        "cv_scores = cross_val_score(polyreg_pipeline, X_train_std, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_rmse = np.sqrt(-cv_scores)\n",
        "\n",
        "print(f\"Cross-Validation RMSE para polinomio de grado 3: \\n{cv_rmse}\")\n",
        "print(f\"RMSE promedio: {cv_rmse.mean():.4f}\")\n",
        "print(f\"Desviación estandar de RMSE: {cv_rmse.std():.4f}\")\n",
        "\n",
        "polyreg_pipeline.fit(X_train_std, y_train)\n",
        "\n",
        "y_pred = polyreg_pipeline.predict(X_test_std)\n",
        "\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mae(y_test, y_pred)\n",
        "r2_test = polyreg_pipeline.score(X_test_std, y_test)\n",
        "\n",
        "print(f\"\\nTest MAE: {mae_test:.4f}\")\n",
        "print(f\"Test RMSE: {rmse_test:.4f}\")\n",
        "print(f\"Test R-squared: {r2_test:.4f}\")"
      ],
      "metadata": {
        "id": "c2yz8HOsgvtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.3 Regresión KNN**"
      ],
      "metadata": {
        "id": "Jm1XUbsA5MAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Buscar el K óptimo de vecinos que más reduce el error MSE"
      ],
      "metadata": {
        "id": "kqzcZcmJnUDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "k_values = range(12, 25)\n",
        "cv_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    model = KNeighborsRegressor(n_neighbors=k)\n",
        "    scores = cross_val_score(model, X_train_std, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "    cv_scores.append(np.mean(scores))\n",
        "\n",
        "plt.plot(k_values, -np.array(cv_scores), marker='o')\n",
        "plt.xlabel('Número de vecinos (K)')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Regresión KNN: MSE vs. Número de vecinos (K)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tIjiP7J2K6tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicar búsqueda de hiperparámetros con Cross-Validation para obtener el KNN regressor con los mejores parámetros"
      ],
      "metadata": {
        "id": "AA0cOfY9na7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=knn, param_distributions=param_grid,\n",
        "                                   n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1,\n",
        "                                   scoring='neg_mean_squared_error')\n",
        "\n",
        "random_search.fit(X_train_std, y_train)\n",
        "\n",
        "print(\"Parámetros del mejor modelo encontrado: \", random_search.best_params_)\n",
        "print(\"Mejor score de cross-validation: \", random_search.best_score_)\n",
        "\n",
        "best_knn = random_search.best_estimator_\n",
        "y_pred = best_knn.predict(X_test_std)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R-squared: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "JXNq6pT_XbNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizar residuos de estimación del mejor modelo KNN"
      ],
      "metadata": {
        "id": "duAkjqBdn2Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_test - y_pred\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred, residuals, color='blue', edgecolors='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
        "plt.title(\"Residuos de estimación\")\n",
        "plt.xlabel(\"Valores estimados\")\n",
        "plt.ylabel(\"Residuos\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, residuals, color='green', edgecolors='k', alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
        "plt.title(\"Residuos vs Valores reales\")\n",
        "plt.xlabel(\"Valores reales\")\n",
        "plt.ylabel(\"Residuos\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gN55DJLwpTww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AJUSTAR MEJOR MODELO Y EXPORTAR OBJETO PKL FINAL**\n"
      ],
      "metadata": {
        "id": "om9Q-CK7yDq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "best_knn = KNeighborsRegressor(weights='distance', n_neighbors=18, metric='euclidean', algorithm='auto')\n",
        "best_knn"
      ],
      "metadata": {
        "id": "FMyh9pY35LpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "best_knn.fit(X_train_std, y_train)\n",
        "y_pred = best_knn.predict(X_test_std)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mae(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R-squared: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "cDthT4ht5LiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exportar PKL del modelo"
      ],
      "metadata": {
        "id": "tWBF3GV12RnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('model_estimacion_estancia_hospitalaria.pkl', 'wb') as file:\n",
        "    pickle.dump(best_knn, file)\n",
        "print(\"Pickle creado exitosamente\")"
      ],
      "metadata": {
        "id": "Q4-mYYQRfMB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('model_estimacion_estancia_hospitalaria.pkl', 'rb') as file:\n",
        "    modelo_knn = pickle.load(file)\n",
        "\n",
        "modelo_knn"
      ],
      "metadata": {
        "id": "97hDREn73qaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar PKL del modelo a S3 bucket"
      ],
      "metadata": {
        "id": "LaNfIOTqV-7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se mencionó al principio, estas credenciales son temporales. En caso de querer probar la carga, por favor solicitarnos la creación de credenciales para la prueba."
      ],
      "metadata": {
        "id": "02nF-crCWFRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws_access_key_id=ASIAQ4FS56V3QHBQZA6P\n",
        "aws_secret_access_key=COPSG9Q3CLAkz/dsOgH93ghVNpNroyX7ptLGx0g2\n",
        "aws_session_token=IQoJb3JpZ2luX2VjEAsaCXVzLXdlc3QtMiJHMEUCIGRucAtge3zx8yjjhB74HnBipQ6otLV1lqsYQqL+KO1JAiEA3J0muf9wyuDghJO6uJf0AI/qiA0l732OmvW5dbkJzcwquQIItP//////////ARABGgwwNjA1MDQ3OTg1ODMiDJ4Oz08UkPeFTKRFlSqNAtVwziBWTXTc0hk/AXw47qucrOEECAcLtGg+L4L3z/t7rceTcA37pz0kMUf/CNppLeVHaeU+uJjf8t+idyL1nJJtDIK1mIy9vMkTFbnFsInPrOaCFZI16BXCGBpE1p4U0t2ns+EpQ5/mWiILXg16647gkFM/SgtMEOKllDV8QXrLNSHCnC97Rrig+zSuyZntbO2rK6Iz7Me2jesi2lxI64W9WtTEADBZrIo6Yw31/cOyk//z5JHyyos4Hm82OpDqu0pAhfMs04d8+/D/rhpG/tC7PAFEA1FpfmvizbdJ+x7FzbdU9sjpgt67uxqYkqPI5QP12t77o42g7GtjQJZDUDyKtUKuB7EzQGr60QbvMJ26tLoGOp0BBG1PuI6VbDGMxaEqiaWAZj/iCXW/0NOprAsLiwcXctU4Sx0cZhyL1Ent9gWsodkm/6CKpouMw0oYnzhi13QRUu8l5ymbl3dCMfJZGYBe6k30JZJtZGEFR8ulRVpF3xKzX1BXd5pnwHTLBizZNvx4CpRthc8AdOAYSb/OYzVGjW5lar9SifPEFZrj1dWpM6XKPxRx5Dg6joWkyMdqZA==\n"
      ],
      "metadata": {
        "id": "bFZEblnhVbAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import pickle\n",
        "from io import BytesIO\n",
        "\n",
        "def cargar_pickle_a_s3(obj, bucket_name, file_key, aws_access_key_id, aws_secret_access_key, aws_session_token):\n",
        "    s3 = boto3.client(\n",
        "        \"s3\",\n",
        "        aws_access_key_id=aws_access_key_id,\n",
        "        aws_secret_access_key=aws_secret_access_key,\n",
        "        aws_session_token=aws_session_token,\n",
        "    )\n",
        "    try:\n",
        "        # Serialize the object to a binary buffer\n",
        "        pickle_buffer = BytesIO()\n",
        "        pickle.dump(obj, pickle_buffer)\n",
        "        pickle_buffer.seek(0)  # Reset buffer pointer to the beginning\n",
        "\n",
        "        # Upload the binary data to the S3 bucket\n",
        "        s3.put_object(Bucket=bucket_name, Key=file_key, Body=pickle_buffer)\n",
        "        print(f\"Objeto PKL cargado exitosamente a  s3://{bucket_name}/{file_key}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error cargando el archivo: {e}\")\n",
        "\n",
        "\n",
        "# Configuración\n",
        "BUCKET_NAME = \"proyectointegrador\"\n",
        "FILE_KEY = \"trusted/model_estimacion_estancia_hospitalaria.pkl\"\n",
        "AWS_ACCESS_KEY_ID = \"ASIAQ4FS56V3QHBQZA6P\"\n",
        "AWS_SECRET_ACCESS_KEY = \"COPSG9Q3CLAkz/dsOgH93ghVNpNroyX7ptLGx0g2\"\n",
        "AWS_SESSION_TOKEN = \"IQoJb3JpZ2luX2VjEAsaCXVzLXdlc3QtMiJHMEUCIGRucAtge3zx8yjjhB74HnBipQ6otLV1lqsYQqL+KO1JAiEA3J0muf9wyuDghJO6uJf0AI/qiA0l732OmvW5dbkJzcwquQIItP//////////ARABGgwwNjA1MDQ3OTg1ODMiDJ4Oz08UkPeFTKRFlSqNAtVwziBWTXTc0hk/AXw47qucrOEECAcLtGg+L4L3z/t7rceTcA37pz0kMUf/CNppLeVHaeU+uJjf8t+idyL1nJJtDIK1mIy9vMkTFbnFsInPrOaCFZI16BXCGBpE1p4U0t2ns+EpQ5/mWiILXg16647gkFM/SgtMEOKllDV8QXrLNSHCnC97Rrig+zSuyZntbO2rK6Iz7Me2jesi2lxI64W9WtTEADBZrIo6Yw31/cOyk//z5JHyyos4Hm82OpDqu0pAhfMs04d8+/D/rhpG/tC7PAFEA1FpfmvizbdJ+x7FzbdU9sjpgt67uxqYkqPI5QP12t77o42g7GtjQJZDUDyKtUKuB7EzQGr60QbvMJ26tLoGOp0BBG1PuI6VbDGMxaEqiaWAZj/iCXW/0NOprAsLiwcXctU4Sx0cZhyL1Ent9gWsodkm/6CKpouMw0oYnzhi13QRUu8l5ymbl3dCMfJZGYBe6k30JZJtZGEFR8ulRVpF3xKzX1BXd5pnwHTLBizZNvx4CpRthc8AdOAYSb/OYzVGjW5lar9SifPEFZrj1dWpM6XKPxRx5Dg6joWkyMdqZA==\"\n",
        "\n",
        "\n",
        "\n",
        "# Subir el PKL\n",
        "cargar_pickle_a_s3(modelo_knn, BUCKET_NAME, FILE_KEY, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN)\n"
      ],
      "metadata": {
        "id": "yh_1jbW5Opuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7C6nvcm4UqpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mx0RwTEmUqm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Relq92JeUqko"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4gSDRdTibI9I",
        "ipl8rcqlbE4v",
        "7PBv9iTNtVTN",
        "9QpvP8U-_4yJ",
        "PvcA1pfDqD5w",
        "h-B1--Zl4wKl",
        "zol8HXA09MDm",
        "NYDlomqJxUHe",
        "w02jQX1l2P3v",
        "NNb3oJ9uwMlN",
        "-mQD53v850_p",
        "v0UFyx9nw0x-",
        "moFNEaMKxrpK",
        "IP4SXYLHUn8f",
        "0rjB-wVfFucA",
        "0f9WXMOQcjTD"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}